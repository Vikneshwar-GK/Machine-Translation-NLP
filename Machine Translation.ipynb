{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Model Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6vfkfB9ttCs"
      },
      "source": [
        "from pickle import load\n",
        "from pickle import dump\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, TimeDistributed, Dropout, Embedding, Bidirectional, LSTM\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyXcJpRSttCt"
      },
      "source": [
        "def load_data(path):\n",
        "#     return load(open(path, 'rb'))\n",
        "    with open(path) as f:\n",
        "        data = f.read()\n",
        "    return data.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25yyn76bttCt"
      },
      "source": [
        "en_sentences = load_data('data\\\\small_vocab_en')\n",
        "fr_sentences = load_data('data\\\\small_vocab_fr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmPE_0aAttCu"
      },
      "source": [
        "def tokenize_text(sentences):\n",
        "    token = Tokenizer()\n",
        "    token.fit_on_texts(sentences)\n",
        "    sequences = token.texts_to_sequences(sentences)\n",
        "    word_index = token.word_index\n",
        "    return sequences, word_index, token\n",
        "\n",
        "# en_sequences, en_word_index = tokenize_text(en_sentences)\n",
        "# print(en_sequences[0],'\\n', en_word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8J49XkGttCu"
      },
      "source": [
        "def pad_sequence(sequences, length = None):\n",
        "    return pad_sequences(sequences, maxlen = length, padding = 'post')\n",
        "# en_Psequences = pad_sequence(en_sequences)\n",
        "# en_Psequences.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi4N5ODlttCu"
      },
      "source": [
        "def preprocess_sequence(sentences, pad_size = None):\n",
        "    sequences, word_index, token = tokenize_text(sentences)\n",
        "    Psequences = pad_sequence(sequences, pad_size)\n",
        "    return Psequences, word_index, token\n",
        "\n",
        "\n",
        "en_Psequences, en_word_index, en_token = preprocess_sequence(en_sentences)\n",
        "fr_Psequences, fr_word_index, fr_token = preprocess_sequence(fr_sentences)\n",
        "fr_Psequences = fr_Psequences.reshape(*fr_Psequences.shape,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwhW158uttCu"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Model  : GRU with custom Embedding and Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byUcLQhPttCu"
      },
      "source": [
        "def GRU_with_EB(en_vocab_size, input_shape, fr_vocab_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim = en_vocab_size + 1, output_dim = 10, input_length = input_shape[1], input_shape = input_shape[1:]))\n",
        "    model.add(Bidirectional(GRU(128, return_sequences = True)))\n",
        "    model.add(TimeDistributed(Dense(128, activation = 'relu')))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(TimeDistributed(Dense(fr_vocab_size + 1, activation = 'softmax')))\n",
        "    \n",
        "    model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model\n",
        "    \n",
        "    \n",
        "    \n",
        "en_Psequences = pad_sequence(en_Psequences, fr_Psequences.shape[1])\n",
        "# en_Psequences = en_Psequences.reshape((-1, fr_Psequences.shape[-2]))\n",
        "GRU_EB_model = GRU_with_EB(len(en_word_index), en_Psequences.shape, len(fr_word_index))\n",
        "GRU_EB_model.summary()\n",
        "\n",
        "result = GRU_EB_model.fit(en_Psequences, fr_Psequences, batch_size = 512, epochs = 100, validation_split = 0.2, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTprqUCvttCu"
      },
      "source": [
        "def process_input(text, token, pad_size = None):\n",
        "#     token.fit_on_texts(text)\n",
        "    sequences = token.texts_to_sequences(text)\n",
        "    Psequences = pad_sequences(sequences, maxlen = pad_size, padding = 'post')\n",
        "    return Psequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnl3VOixeEP"
      },
      "source": [
        "def en_fr_translation(logits, token):\n",
        "    index_word = {id : word for word, id in token.word_index.items()}\n",
        "#     index_word[0] = '<PAD>'\n",
        "    return ' '.join([index_word.get(pred,'') for pred in np.argmax(logits, 1)])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvf7oSMTxog3"
      },
      "source": [
        "input_sentence = input(\"Enter a Enter Sentence :\\n\")\n",
        "\n",
        "input_text = []\n",
        "input_text.append(input_sentence)\n",
        "Pinput_text = process_input(input_text, en_token, 21)\n",
        "print(\"\\nTranslated French Sentence : \\n\", en_fr_translation(GRU_EB_model.predict(Pinput_text)[0], fr_token))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}